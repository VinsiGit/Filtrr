{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:51:05.471926600Z",
     "start_time": "2024-03-04T10:51:05.431252500Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from transformers import pipeline, Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.snowball import EnglishStemmer\n",
    "from googletrans import Translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# TODO: add privacy extraction\n",
    "# TODO: add check if start isn't zero so remove from results\n",
    "# TODO: layer tokens in batches of 50\n",
    "# TODO: add keyword checker\n",
    "\n",
    "class Preprocessor:\n",
    "    \"\"\"\n",
    "    This class contains the basic preprocessor pipeline that's used to extract keywords themed around skills.\n",
    "\n",
    "    Attributes:\n",
    "        __dir_skill (str): The directory path where the skill preprocessor model is stored.\n",
    "        __dir_knowledge (str): The directory path where the knowledge preprocessor model is stored.\n",
    "        _window_size (int): The window size used in the preprocessor pipeline.\n",
    "\n",
    "    Methods:\n",
    "        __init__: Initializes the Preprocessor class with default or user-specified parameters.\n",
    "        preprocess_input: Preprocesses input and gives skills & knowledge back\n",
    "    \"\"\"\n",
    "    def __init__(self, window_size: int = 8, preprocessor_dir_skill: str = \"./preprocessor/skill/\", preprocessor_dir_knowledge: str = \"./preprocessor/knowledge/\"):\n",
    "        \"\"\"\n",
    "        Initializes the Preprocessor class with default or user-specified parameters.\n",
    "\n",
    "        Args:\n",
    "            window_size (int): The window size used in the preprocessor pipeline. Default is 8.\n",
    "            preprocessor_dir_skill (str): The directory path where the skill preprocessor model is stored.\n",
    "                Default is \"./preprocessor/skill/\".\n",
    "            preprocessor_dir_knowledge (str): The directory path where the knowledge preprocessor model is stored.\n",
    "                Default is \"./preprocessor/knowledge/\".\n",
    "        \"\"\"\n",
    "        self._dir_skill = preprocessor_dir_skill\n",
    "        self._dir_knowledge = preprocessor_dir_knowledge\n",
    "        self._window_size = window_size\n",
    "        self._skill_preprocessor = self.__load_model(dir=self._dir_skill, model_name=\"jjzha/jobbert_skill_extraction\")\n",
    "        self._knowledge_preprocessor = self.__load_model(dir=self._dir_knowledge, model_name=\"jjzha/jobbert_knowledge_extraction\")\n",
    "        \n",
    "    def __load_model(self, dir:str, model_name:str) -> Pipeline:\n",
    "        \"\"\"\n",
    "        Loads a preprocessor model from the specified directory.\n",
    "\n",
    "        Args:\n",
    "            dir (str): The directory path where the preprocessor model is stored.\n",
    "            model_name (str): The name of the preprocessor model to load.\n",
    "\n",
    "        Returns:\n",
    "            object: The preprocessor model loaded from the specified directory.\n",
    "        \"\"\"\n",
    "        if not os.path.exists(dir) or not os.listdir(dir):\n",
    "            token_classifier = pipeline(model=model_name, aggregation_strategy=\"first\")\n",
    "            token_classifier.save_pretrained(dir)\n",
    "        return pipeline(model=dir, task=\"ner\")   \n",
    "    \n",
    "    def __translate_to_english(self, text:str) -> str:\n",
    "        translator = Translator()\n",
    "        translated_text = translator.translate(text,src='auto', dest='en').text\n",
    "        return translated_text\n",
    "    \n",
    "    \n",
    "    def preprocess_input(self, email:any) -> dict[str, list[dict[str, str]] | list[dict[str, str]]]:\n",
    "        \"\"\"\n",
    "        Preprocesses the input email to extract skills and knowledge.\n",
    "    \n",
    "        Args:\n",
    "            email (json): The input email to be preprocessed.\n",
    "    \n",
    "        Returns:\n",
    "            dict[str, list[dict[str, str]] | list[dict[str, str]]]: A dictionary containing lists of dictionaries,\n",
    "                where each dictionary represents a skill or knowledge term with its corresponding score and type.\n",
    "                The dictionary has two keys: 'skill' and 'knowledge', each containing a list of dictionaries.\n",
    "    \n",
    "        Note:\n",
    "            This function performs the following preprocessing steps:\n",
    "            1. Translates the email text to English.\n",
    "            2. Tokenizes the text and converts it to lowercase.\n",
    "            3. Removes stopwords and non-alphabetic tokens.\n",
    "            4. Stems the remaining tokens.\n",
    "            5. Processes the tokens using separate preprocessors for skills and knowledge.\n",
    "            6. Combines the output of the preprocessors into a dictionary.\n",
    "    \n",
    "        Example:\n",
    "                # Initialize the object\n",
    "                preprocessor = Preprocessor()\n",
    "                \n",
    "                # Define an example email\n",
    "                email = {\n",
    "                    'text_body': 'This is a sample email containing information about programming and machine learning.'\n",
    "                }\n",
    "                \n",
    "                # Preprocess the email\n",
    "                result = preprocessor.preprocess_input(email)\n",
    "                \n",
    "                # Access the extracted skills and knowledge\n",
    "                skills = result['skill']\n",
    "                knowledge = result['knowledge']\n",
    "        \"\"\"\n",
    "\n",
    "        text_en = self.__translate_to_english(email['text_body'])\n",
    "\n",
    "        # Tokenize the text using NLTK\n",
    "        tokens = word_tokenize(text_en.lower()) #nope this is dumb\n",
    "        \n",
    "        stop_words = set(stopwords.words('english'))\n",
    "        tokens = [token for token in tokens if token.isalpha() and token not in stop_words]\n",
    "        \n",
    "        stemmer = EnglishStemmer()\n",
    "        tokens = [stemmer.stem(token) for token in tokens]\n",
    "        \n",
    "        # Process tokens using skill_preprocessor\n",
    "        skill_output = [self._skill_preprocessor(' '.join(tokens[i-self._window_size:i+self._window_size])) for i in range(self._window_size, len(tokens), self._window_size)] #context based preprocessing using sliding window\n",
    "        filtered_skill_output = [item for item in skill_output if item]  # Filter out empty arrays\n",
    "        if filtered_skill_output:\n",
    "            transformed_skill_output = [{'word': item['word'], 'score': item['score'], 'type': 'skill'} for item in filtered_skill_output[0]]\n",
    "        else:\n",
    "            transformed_skill_output = []\n",
    "        \n",
    "        # Process tokens using knowledge_preprocessor\n",
    "        knowledge_output = [self._knowledge_preprocessor(' '.join(tokens[i-self._window_size:i+self._window_size])) for i in range(self._window_size, len(tokens), self._window_size)]\n",
    "        filtered_knowledge_output = [item for item in knowledge_output if item]  # Filter out empty arrays\n",
    "        transformed_knowledge_output = [{'word': item['word'], 'score': item['score'], 'type': 'knowledge'} for item in filtered_knowledge_output[0]]\n",
    "        if filtered_knowledge_output:\n",
    "            transformed_knowledge_output_output = [{'word': item['word'], 'score': item['score'], 'type': 'skill'} for item in filtered_knowledge_output[0]]\n",
    "        else:\n",
    "            transformed_knowledge_output = []\n",
    "\n",
    "\n",
    "        combined_output = {'skill':transformed_skill_output,'knowledge': transformed_knowledge_output}\n",
    "\n",
    "        return combined_output\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:51:05.504512900Z",
     "start_time": "2024-03-04T10:51:05.452362900Z"
    }
   },
   "id": "8da47ed5078be26b"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "email =  {\n",
    "    \"item_id\": 0,\n",
    "    \"sender\": \"a1d400258b5c6e3d97307b2c949ffe01fe0aa27ab02ef1c351a7bfa6e0f300a3\",\n",
    "    \"sender_email\": \"6fedc8e86e6e05504fefcdce51f8f73b69f5fd104c23dc5e9dba6c64e5536ffd\",\n",
    "    \"datetime_received\": 1707207587000,\n",
    "    \"sensitivity\": \"Normal\",\n",
    "    \"subject\": \"Datawarehousing Specialist (4. Expert (10+)) SWI000876 - For Swift\",\n",
    "    \"text_body\": \"ENKEL RECHTSTREEKS, GEEN TUSSENPARTIJEN AUB\\r\\n\\r\\nVOORRANG VASTE MEDEWERKERS\\r\\n\\r\\n\\r\\n\\r\\nHallo collega\\u2019s,\\r\\n\\r\\n\\r\\n\\r\\nVoor Swift zoeken we een Datawarehousing Specialist (4. Expert (10+)) SWI000876 die voldoet aan volgende beschrijving:\\r\\n\\r\\n\\r\\n\\r\\nUiterste reactiedatum: 16/02/2024\\r\\n\\r\\nGewenste startdatum: 01/03/2024\\r\\n\\r\\nEinddatum: 31/08/2024\\r\\n\\r\\n\\r\\n\\r\\nReferentie: SWI000876\\r\\n\\r\\nTitel: Datawarehousing Specialist (4. Expert (10+)) SWI000876\\r\\n\\r\\nLocatie: THE NETHERLANDS - ZOETERWOUDE (ENERGIEWEG 33, 2382 NC ZOETERWOUDE, NEDERLAND)\\r\\n\\r\\nStatus: Gepubliceerd\\r\\n\\r\\nType contract: Time & material\\r\\n\\r\\nCategorie: Niet van toepassing\\r\\n\\r\\nAantal personen: 1\\r\\n\\r\\nAfdeling: Human Resource (HR)\\r\\n\\r\\n\\r\\n\\r\\nOmschrijving\\r\\n\\r\\n\\r\\n\\r\\nThe project for which the candidate will be assigned is called Digital Dashboards, having the goal of building executive dashboarding for Swift. The ideal candidate will have an extensive background and expertise in MS Power BI, with both the ability to design the data model, as well as the reports and dashboards.\\r\\n\\r\\nThe candidate will join the project team and will have a key role to play, not just delivering on the scope of the project, but also training the team on that technology since it is still quite new at Swift.\\r\\n\\r\\n\\r\\nOpdracht informatie\\r\\n\\r\\n\\r\\n\\r\\nProjectnaam: Digital Dashboards\\r\\n\\r\\nWerkregime: Voltijds\\r\\n\\r\\n\\r\\n\\r\\nVaardigheden\\r\\n\\r\\n\\r\\n\\r\\nSPECIFIEKE VAARDIGHEDEN\\r\\n\\r\\n\\r\\n\\r\\nData Modeling: Expert (10+)\\r\\n\\r\\nETL Development: Expert (10+)\\r\\n\\r\\nMS Power Bi: Expert (10+)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nIndien jullie geschikte kandidaten hebben ontvang ik graag hun beschikbaarheid, CV en kostprijs.\\r\\n\\r\\n\\r\\n\\r\\nAlvast hartelijk bedankt.\\r\\n\\r\\n\\r\\n[signature_1929168496]\\r\\n\\r\\nChannice \\r\\n\\r\\nExecutive Assistant - Business and sales support\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nDe Cronos Groep nv\\r\\n\\r\\nVeldkant 33A, 2550 Kontich\\r\\n\\r\\n\\r\\n\",\n",
    "    \"label\": \"BI_ENGINEER\",\n",
    "    \"keywords\": [\n",
    "      \"Datawarehousing Specialist\",\n",
    "      \"MS Power BI\",\n",
    "      \"Data Modeling\",\n",
    "      \"ETL Development\"\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:51:05.504512900Z",
     "start_time": "2024-03-04T10:51:05.461892100Z"
    }
   },
   "id": "c982bb06c5c6eb44"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "preprocessor = Preprocessor()\n",
    "\n",
    "# loads in 6s and 660ms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:51:20.588681900Z",
     "start_time": "2024-03-04T10:51:05.469424900Z"
    }
   },
   "id": "c25a41f523be4d3a"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'skill': [{'word': 'call', 'score': 0.97733104, 'type': 'skill'},\n  {'word': 'digit', 'score': 0.9938543, 'type': 'skill'},\n  {'word': 'dash', 'score': 0.9979796, 'type': 'skill'},\n  {'word': '##board', 'score': 0.99763584, 'type': 'skill'},\n  {'word': 'goal', 'score': 0.9501919, 'type': 'skill'},\n  {'word': 'build', 'score': 0.37625405, 'type': 'skill'},\n  {'word': 'ex', 'score': 0.9443724, 'type': 'skill'},\n  {'word': '##ec', 'score': 0.8362159, 'type': 'skill'},\n  {'word': '##ut', 'score': 0.71035093, 'type': 'skill'}],\n 'knowledge': [{'word': '##s', 'score': 0.6861965, 'type': 'knowledge'},\n  {'word': 'power', 'score': 0.80664647, 'type': 'knowledge'},\n  {'word': 'bi', 'score': 0.55603504, 'type': 'knowledge'},\n  {'word': '##bil', 'score': 0.5497193, 'type': 'knowledge'},\n  {'word': 'design', 'score': 0.83985806, 'type': 'knowledge'},\n  {'word': 'data', 'score': 0.87365234, 'type': 'knowledge'}]}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.preprocess_input(email)\n",
    "\n",
    "# classification takes 1s and 180 ms"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:51:22.991316800Z",
     "start_time": "2024-03-04T10:51:20.604395400Z"
    }
   },
   "id": "7faebae92cfc541c"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-04T10:51:23.034005300Z",
     "start_time": "2024-03-04T10:51:22.977886400Z"
    }
   },
   "id": "71b07b974bff8850"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
