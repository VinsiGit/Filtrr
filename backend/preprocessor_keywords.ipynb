{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 306,
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from transformers import pipeline\n",
    "from googletrans import Translator\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import words"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:42:21.690769200Z",
     "start_time": "2024-03-05T08:42:21.685769600Z"
    }
   },
   "id": "d7134b06f3061689"
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "outputs": [],
   "source": [
    "class Preprocessor:\n",
    "    def __init__(self):\n",
    "        \n",
    "        self._translator = Translator()\n",
    "        \n",
    "        nltk.download('punkt')\n",
    "        nltk.download('stopwords')\n",
    "        nltk.download('wordnet')\n",
    "        nltk.download('words')\n",
    "        \n",
    "        self.words = set(words.words('en')+stopwords.words('english'))\n",
    "        self.lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    def __load_model(self, dir:str, model_name:str):\n",
    "        if not os.path.exists(dir) or not os.listdir(dir):\n",
    "            token_classifier = pipeline(model=model_name, aggregation_strategy=\"first\")\n",
    "            token_classifier.save_pretrained(dir)\n",
    "        return pipeline(model=dir, task=\"ner\")\n",
    "\n",
    "    def __regex_privacy(self,text:str) -> str:\n",
    "        patterns = [\n",
    "            r'\\r',  # Matches carriage return\n",
    "            r'\\n',  # Matches newline\n",
    "            r'https?:\\/\\/(www\\.)?[-a-zA-Z0-9@:%._\\+~#=]{1,256}\\.[a-zA-Z0-9()]{1,6}\\b([-a-zA-Z0-9()!@:%_\\+.~#?&\\/\\/=]*)',  # Matches URLs\n",
    "            r'^[\\+]?[(]?[0-9]{3}[)]?[-\\s\\.]?[0-9]{3}[-\\s\\.]?[0-9]{4,6}$',  # Matches phone numbers\n",
    "            r'[0-9]',  # Matches digits\n",
    "            r'-',  # Matches hyphens\n",
    "            r'[\\[\\](){}<>]',  # Matches brackets and parentheses\n",
    "            r'[,\\.;:!?\\&+_\\/]'  # Matches common punctuation\n",
    "        ]\n",
    "        for pattern in patterns:\n",
    "            text = re.sub(pattern, '  ', text)\n",
    "        return text\n",
    "\n",
    "    def __clean_text(self,text:str) -> str:\n",
    "        text_multi_space = text.replace(' ','_')\n",
    "        text_cleaned = self.__regex_privacy(text_multi_space)\n",
    "        return text_cleaned\n",
    "\n",
    "    def __translate_to_english(self, text:str) -> str:\n",
    "        translated_text = self._translator.translate(text, src='auto', dest='en').text\n",
    "        return translated_text\n",
    "\n",
    "    def __tokenize(self,text:str) -> list[str]:\n",
    "        tokens = word_tokenize(text)\n",
    "        lemmatized_tokens = [self.lemmatizer.lemmatize(token) for token in tokens]\n",
    "        filtered_tokens = [token.lower() for token in lemmatized_tokens if token not in self.words]\n",
    "        return filtered_tokens\n",
    "\n",
    "    def preprocess(self, text:str) -> str:\n",
    "        clean_text = self.__clean_text(text)\n",
    "        text_english = self.__translate_to_english(clean_text)\n",
    "        clean_english_text = self.__clean_text(text_english)\n",
    "        tokens = self.__tokenize(clean_english_text)\n",
    "        unique_tokens = list(set(tokens))\n",
    "        return unique_tokens"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:42:21.697770300Z",
     "start_time": "2024-03-05T08:42:21.694771Z"
    }
   },
   "id": "9aa0b020223a37e2"
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "outputs": [],
   "source": [
    "email = {\n",
    "    \"item_id\": 0,\n",
    "    \"sender\": \"a1d400258b5c6e3d97307b2c949ffe01fe0aa27ab02ef1c351a7bfa6e0f300a3\",\n",
    "    \"sender_email\": \"6fedc8e86e6e05504fefcdce51f8f73b69f5fd104c23dc5e9dba6c64e5536ffd\",\n",
    "    \"datetime_received\": 1707207587000,\n",
    "    \"sensitivity\": \"Normal\",\n",
    "    \"subject\": \"Datawarehousing Specialist (4. Expert (10+)) SWI000876 - For Swift\",\n",
    "    \"text_body\": \"ENKEL RECHTSTREEKS, GEEN TUSSENPARTIJEN AUB\\r\\n\\r\\nVOORRANG VASTE MEDEWERKERS\\r\\n\\r\\n\\r\\n\\r\\nHallo collega\\u2019s,\\r\\n\\r\\n\\r\\n\\r\\nVoor Swift zoeken we een Datawarehousing Specialist (4. Expert (10+)) SWI000876 die voldoet aan volgende beschrijving:\\r\\n\\r\\n\\r\\n\\r\\nUiterste reactiedatum: 16/02/2024\\r\\n\\r\\nGewenste startdatum: 01/03/2024\\r\\n\\r\\nEinddatum: 31/08/2024\\r\\n\\r\\n\\r\\n\\r\\nReferentie: SWI000876\\r\\n\\r\\nTitel: Datawarehousing Specialist (4. Expert (10+)) SWI000876\\r\\n\\r\\nLocatie: THE NETHERLANDS - ZOETERWOUDE (ENERGIEWEG 33, 2382 NC ZOETERWOUDE, NEDERLAND)\\r\\n\\r\\nStatus: Gepubliceerd\\r\\n\\r\\nType contract: Time & material\\r\\n\\r\\nCategorie: Niet van toepassing\\r\\n\\r\\nAantal personen: 1\\r\\n\\r\\nAfdeling: Human Resource (HR)\\r\\n\\r\\n\\r\\n\\r\\nOmschrijving\\r\\n\\r\\n\\r\\n\\r\\nThe project for which the candidate will be assigned is called Digital Dashboards, having the goal of building executive dashboarding for Swift. The ideal candidate will have an extensive background and expertise in MS Power BI, with both the ability to design the data model, as well as the reports and dashboards.\\r\\n\\r\\nThe candidate will join the project team and will have a key role to play, not just delivering on the scope of the project, but also training the team on that technology since it is still quite new at Swift.\\r\\n\\r\\n\\r\\nOpdracht informatie\\r\\n\\r\\n\\r\\n\\r\\nProjectnaam: Digital Dashboards\\r\\n\\r\\nWerkregime: Voltijds\\r\\n\\r\\n\\r\\n\\r\\nVaardigheden\\r\\n\\r\\n\\r\\n\\r\\nSPECIFIEKE VAARDIGHEDEN\\r\\n\\r\\n\\r\\n\\r\\nData Modeling: Expert (10+)\\r\\n\\r\\nETL Development: Expert (10+)\\r\\n\\r\\nMS Power Bi: Expert (10+)\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nIndien jullie geschikte kandidaten hebben ontvang ik graag hun beschikbaarheid, CV en kostprijs.\\r\\n\\r\\n\\r\\n\\r\\nAlvast hartelijk bedankt.\\r\\n\\r\\n\\r\\n[signature_1929168496]\\r\\n\\r\\nChannice \\r\\n\\r\\nExecutive Assistant - Business and sales support\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\n\\r\\nDe Cronos Groep nv\\r\\n\\r\\nVeldkant 33A, 2550 Kontich\\r\\n\\r\\n\\r\\n\",\n",
    "    \"label\": \"BI_ENGINEER\",\n",
    "    \"keywords\": [\n",
    "      \"Datawarehousing Specialist\",\n",
    "      \"MS Power BI\",\n",
    "      \"Data Modeling\",\n",
    "      \"ETL Development\"\n",
    "    ]\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:42:21.705771600Z",
     "start_time": "2024-03-05T08:42:21.700769800Z"
    }
   },
   "id": "93e478f199227815"
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/jurrean/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/jurrean/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/jurrean/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package words to /home/jurrean/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "preprocessor = Preprocessor()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:42:21.785089400Z",
     "start_time": "2024-03-05T08:42:21.703770800Z"
    }
   },
   "id": "550d9ca1f6164510"
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "outputs": [
    {
     "data": {
      "text/plain": "['information',\n 'title',\n 'datawarehousing',\n 'signature',\n 'cronos',\n 'kontich',\n 'number',\n 'assistant',\n 'de',\n 'energewoude',\n 'executive',\n 'ideal',\n 'description',\n 'start',\n 'join',\n 'development',\n 'sales',\n 'candidate',\n 'background',\n 'publishedcategory',\n 'power',\n 'theability',\n 'name',\n 'field',\n 'support',\n 'reaction',\n 'work',\n 'specific',\n 'hello',\n 'nederland',\n 'groupnv',\n 'location',\n 'human',\n 'dashboarding',\n 'swift',\n 'bi',\n 'full',\n 'data',\n 'zoeterwoude',\n 'delivering',\n 'business',\n 'ms',\n 'assignment',\n 'called',\n 'an',\n 'skills',\n 'be',\n 'project',\n 'swi',\n 'department',\n 'non',\n 'digital',\n 'building',\n 'have',\n 'team',\n 'quitenew',\n 'netherlands',\n 'goal',\n 'regime',\n 'etl',\n 'cv',\n 'expertise',\n 'hr',\n 'expert',\n 'dashboards',\n 'only',\n 'modeling',\n 'status',\n 'exualive',\n 'if',\n 'resource',\n 'having',\n 'assigned',\n 'excellent',\n 'specialist']"
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessor.preprocess(email['text_body'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-05T08:42:21.994284600Z",
     "start_time": "2024-03-05T08:42:21.837831900Z"
    }
   },
   "id": "df140a01e9c181fc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
